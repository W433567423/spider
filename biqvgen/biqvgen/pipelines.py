# Define your item pipelines here
#
# Don't forget to add your pipeline to the ITEM_PIPELINES setting
# See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html


# useful for handling different item types with a single interface
from biqvgen.utils import conn, console
from rich.progress import BarColumn, TimeRemainingColumn, MofNCompleteColumn


class BiqvgenPipeline:
    novel_list = []  # å°è¯´åˆ—è¡¨

    #  å¤„ç†item
    def process_item(self, item, spider):
        novel = {
            "novel_id": item["novel_id"],
            "novel_name": item["novel_name"],
            "novel_cover": item["novel_cover"],
            "novel_author": item["novel_author"],
            "novel_category": item["novel_category"],
            "write_status": item["write_status"],
            "updated_time": item["updated_time"],
            "intro": item["intro"],
        }
        novel["intro"] = item["intro"].replace("\xa0", "").replace("\u3000", "")
        self.novel_list.append(novel)

        # if len(self.novel_list) == 1000:
        #     self.bulk_insert_to_mysql(self.novel_list, spider)
        #     del self.novel_list[:]

    # å¼€å¯çˆ¬è™«
    def open_spider(self, spider):
        # åˆ›å»ºæ•°æ®åº“
        global conn
        conn.ping(reconnect=True)
        cursor = conn.cursor()  # åˆ›å»ºæ¸¸æ ‡
        # åˆ›å»ºæ•°æ®è¡¨
        cursor.execute("DROP TABLE IF EXISTS novels;")
        cursor.execute(
            """
                CREATE TABLE IF NOT EXISTS novels(
                novel_id INT PRIMARY KEY COMMENT 'ç¬”è¶£é˜å°è¯´id',
                novel_name VARCHAR(255) COMMENT 'å°è¯´å' not null,
                novel_cover VARCHAR(255) COMMENT 'å°è¯´å°é¢',
                novel_author VARCHAR(255) COMMENT 'å°è¯´ä½œè€…',
                novel_category VARCHAR(255) COMMENT 'å°è¯´åˆ†ç±»',
                write_status VARCHAR(255) COMMENT 'å°è¯´è¿è½½çŠ¶æ€',
                updated_time VARCHAR(255) COMMENT 'å°è¯´å‘å¸ƒæ—¶é—´',
                intro TEXT COMMENT 'å°è¯´ç®€ä»‹',
                is_extra BOOLEAN DEFAULT FALSE COMMENT 'æ˜¯å¦å·²æ·»åŠ é¢å¤–ä¿¡æ¯(è¿è½½æƒ…å†µã€äººæ°”ã€è¯„åˆ†ç­‰)',
                is_chapter BOOLEAN DEFAULT FALSE COMMENT 'æ˜¯å¦å·²æ·»åŠ ç« èŠ‚ä¿¡æ¯',
                abnormal BOOLEAN DEFAULT FALSE COMMENT 'æ˜¯å¦å¼‚å¸¸',
                file_path VARCHAR(255) COMMENT 'å°è¯´æ–‡ä»¶è·¯å¾„'
                );
            """
        )
        conn.commit()
        cursor.close()
        # console.log("æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")
        pass

    # å…³é—­çˆ¬è™«
    def close_spider(self, spider):
        # ä¿å­˜åˆ°æ•°æ®åº“
        # self.bulk_insert_to_mysql(self.novel_list, spider)
        console.log("ğŸš€ ~ self.novel_list, spider:", len(self.novel_list))
        console.log(self.novel_list[:1])
        pass

    # æ‰¹é‡æ’å…¥åˆ°æ•°æ®åº“
    def bulk_insert_to_mysql(self, data, spider):
        console.log("å¼€å§‹æ‰¹é‡æ’å…¥åˆ°æ•°æ®åº“")
        global conn
        conn.ping(reconnect=True)
        cursor = conn.cursor()  # åˆ›å»ºæ¸¸æ ‡
        cursor.executemany(
            "INSERT INTO novels(novel_id, novel_name, novel_cover, novel_author, novel_category, write_status, updated_time, intro) VALUES(%(novel_id)s, %(novel_name)s, %(novel_cover)s, %(novel_author)s, %(novel_category)s, %(write_status)s, %(updated_time)s, %(intro)s);",
            (data),
        )
        conn.commit()
        cursor.close()
